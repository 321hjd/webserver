---------------问题-----------------
1.无法访问web页面时，如何查找问题所在？




服务器组成模块：
	1.I/O处理单元。I/O模型，高效的事件处理模式       ----------------------------- 监听请求
		1）客户连接是随机的异步事件，需要使用I/O模型对该事件进行监听。
		2）因为需要同时监听多个用户连接请求，所以需要I/O复用技术（如select/poll/epoll_wait）
	2.逻辑单元。高效的并发处理模式，高效的逻辑处理方式-有限状态机 ---------------- 处理请求
		1）逻辑单元用于读取和处理客户请求、并返回处理结果。逻辑单元可以是子进程或子线程（因此是多个逻辑单元，业务进程/线程）。
		2）由于服务器在处理一个客户请求的同时需要继续监听其它客户请求，因此需要“并发处理模式”（否则就变成效率低下的串行服务器了）
	3.存储单元
		1）本地数据库、文件或缓存

服务器模型
	1.C/S（client/server）模型：所有客户端通过访问服务器获取所需资源
		1）运行逻辑：服务器启动后，首先创建一个（或多个）监听socket，并调用bind函数将其绑定到服务器感兴趣的端口上，然后调用listen函数等待客户连接。服务器稳定运行之后，客户端就可以调用connect函数向服务器发起连接了。
		2）适用场景：资源相对集中，服务器是通信中心，访问量大时可能响应较慢。
	2.P2P（Peer to Peer，点对点）模型：
		1）运行逻辑：网络中所有主机地位相等（如北邮人pt、磁链），每台主机在消耗服务的同时也为别人提供服务，实现资源的共享。需要一台“发现服务器”，提供查找服务，让每台主机尽快找到所需资源。
		2）缺陷：当用户之间传输的请求过多时，网络的负载将加重；主机之间很难互相发现

服务器编程框架
	1）I/O处理单元。处理客户连接，读写网络数据（服务器机群——作为接入服务器，实现负载均衡）
		等待并接受新的客户连接，接收客户数据，将服务器响应数据返回给客户端（数据收发可能不在I/O处理单元执行，也可能在逻辑单元，具体取决于采用的事件处理模式）—— 有哪些事件处理模式？Reactor/Proactor
	2）逻辑单元。业务进程或线程（并发，多进程/线程）（服务器机群——逻辑服务器）
		分析、处理客户数据，将结果传递给I/O处理单元或直接发给客户端
	3）存储单元。本地数据库、文件或缓存（服务器机群——数据库服务器）
	4）请求队列。各单元之间的通信方式的抽象。（服务器机群——各服务器间的永久TCP连接,提高数据交换效率）
		I/O处理单元接收到客户请求时，需要以某种方式通知一个逻辑单元来处理该请求。同样，多个逻辑单元同时访问一个存储单元时，也需要采用某种机制来协调处理竞态条件（调度？）。请求队列通常被实现为池的一部分

----------------------------------------------I/O模型----------------------------------------
	1）阻塞I/O、非阻塞I/O（应用于文件描述符，描述系统调用的运行逻辑）
		阻塞I/O：程序阻塞于读写函数
		非阻塞I/O：立即返回，不管事件是否发生，若事件没有发生，系统调用返回-1（和出错一样，需要通过errno区分两种情况）。只有在事件已经发生的情况下操作非阻塞I/O（读、写等），才能提高程序的效率。因此，非阻塞I/O通常要和其他I/O通知机制一起使用，比如I/O复用和SIGIO信号
	2）I/O复用（最常用的I/O通知机制）
		应用程序通过 I/O复用函数 “向内核注册一组事件”（如用户连接事件），内核通过 I/O复用函数 把其中就绪的事件（有用户请求到达）通知给应用程序。常用的I/O复用函数是select、poll和epoll_wait（即应用程序与内核的消息交换接口）
		注意：I/O复用函数本身是阻塞的，它们能提高程序效率的原因在于它们具有同时监听多个I/O事件的能力
	3）信号驱动I/O
		SIGIO信号可以用于通知I/O事件。为一个文件描述符指定宿主进程，被指定的宿主进程将捕获SIGIO信号，当该文件描述符上有事件发生，SIGIO的信号处理函数将被触发（可以在该信号处理函数中对目标文件描述符执行非阻塞I/O操作，即数据读写）
	4）同步I/O模型 —— 阻塞I/O、I/O复用、信号驱动I/O
		<1>阻塞I/O：程序阻塞于读写函数
		<2>I/O复用：程序阻塞于I/O复用系统调用，但可同时监听多个I/O事件，且对I/O本身的读写操作是非阻塞的
		<3>SIGIO信号驱动I/O：信号触发于读写就绪事件，用户程序（信号处理函数）执行读写操作。没有阻塞阶段
		同步I/O：向应用程序通知“I/O就绪事件”，I/O的读写操作，都是在I/O事件发生之后，由“应用程序完成”。
	5）异步I/O模型
		读写操作立即返回，而不管I/O是否阻塞。没有阻塞阶段。
		异步I/O：向应用程序（工作线程/逻辑单元）通知“I/O完成事件”，读写操作由“内核完成”后通过信号或其它机制通知应用程序数据可用，去进行业务逻辑操作。

------------------------------------------高效的事件处理模式----------------------------------
1.服务器通常需要处理的三类事件
	1）I/O事件
	2）信号
	3）定时事件

2.两类高效的事件处理模式：Reactor（基于同步I/O模型）和Proactor（基于异步I/O模型）

3.Reactor
	1）工作模式：主线程（I/O处理单元）只负责监听文件描述上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元）。读写数据、接受新连接、处理客户请求都在工作线程完成
	2）基于同步I/O模型（以epoll_wait为例）的Reactor模式工作流程
		<1>主线程往epoll内核事件表注册socket上的“读就绪事件”（指的是读客户请求）
		<2>主线程调用epoll_wait等待socket上有数据可读
		<3>当socket上有数据可读时，epoll_wait通知主线程。主线程则将socket可读事件放入请求队列。
		<4>睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求（如读、写数据），然后往epoll内核事件表中注册该socket上的“写就绪事件”（指的是写客户请求处理结果）
		<5>主线程调用epoll_wait等待socket可写
		<6>当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列。
		<7>睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果。

		问题：为什么工作线程完成客户请求处理后还需要注册“写就绪事件”，让其它工作线程去往socket写入处理结果，而不是处理完成后直接写入结果？
		推测是因为如果采用读写锁，写需要加锁，如果读写都由同一个线程完成，读写锁就没有意义了？

4.Proactor
	1）工作模式：将所有I/O操作都交给主线程和内核处理，工作线程仅负责业务逻辑（更符合上面描述的服务器编程框架）
	2）基于异步I/O模型（以aio_read和aio_write为例）实现的Proactor模式工作流程
		<0>主线程通过epoll_wait监听socket上的连接请求事件，而不检测连接socket上的读写事件。连接完成后……
		<1>主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序
		<2>主线程继续处理其他逻辑
		<3>当socket上的数据被读入用户缓冲区后，内核将向应用程序发送一个“信号”（也可以是其它机制，这里以信号为例），以通知应用程序数据已经可用
		<4>应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后，调用aio_write函数向内核注册socket上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操
作完成时如何通知应用程序
		<5>主线程继续处理其他逻辑
		<6>当用户缓冲区的数据被写入socket之后，内核将向应用程序发送一个“信号”，以通知应用程序数据已经发送完毕
		<7>应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭socket

	Reactor和Proactor的优劣如何？各自适用于什么场景？

5.用同步I/O模拟Proactor模式（项目用的这种事件处理模式）
	1）原理：“主线程执行数据读写操作”，读写完成之后，主线程向工作线程通知这一“完成事件”。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理（即Proactor的工作模式）。
	2）工作流程：
		<1>主线程往epoll内核事件表中注册socket上的读就绪事件
		<2>主线程调用epoll_wait等待socket上有数据可读
		<3>当socket上有数据可读时，epoll_wait通知“主线程”（注意如果是基于异步I/O模型的Proactor，此处是通知工作线程）。主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列
		<4>睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件
		<5>主线程调用epoll_wait等待socket可写
		<6>当socket可写时，epoll_wait通知“主线程”。主线程往socket上写入服务器处理客户请求的结果


--------------------------------------高效的并发处理模式------------------------------------
1.为什么要实现并发处理模式？
	因为I/O操作的速度远没有CPU计算速度快，让程序阻塞于I/O操作将浪费大量的CPU时间。如果程序有多个进程或多个线程，那么当前被I/O操作所阻塞的执行进程/线程可主动放弃CPU（或由操作系统来调度），并将执行权转移到其他进程/线程，从而提高CPU的利用率。
	所以对于计算密集型的程序，并发没什么优势，反而可能因为任务切换使得效率降低。并发适用于I/O密集型程序。

2.并发模式
	1）定义：I/O处理单元和多个逻辑单元之间协调完成任务的方法
	2）两种并发编程模式：半同步/半异步（half-sync/half-async）模式和领导者/追随者（Leader/Followers）模式

3.半同步/半异步
	1）同步/异步的概念：
		I/O模型中：“同步”和“异步”区分的是内核向应用程序通知的是何种I/O事件（是就绪事件还是完成事件），以及该由谁来完成I/O读写（是应用程序(工作线程)还是内核）
		并发模式中：“同步”指的是程序完全按照代码序列的顺序执行；“异步”指的是程序的执行需要由系统事件来驱动（比如中断、信号等）
	2）同步/异步线程的优劣
		<1>同步：执行效率低、实时性差，但实现逻辑简单
		<2>异步：执行效率高、实时性好，但实现逻辑复杂
		<3>半同步/半异步：同时使用同步线程和异步线程实现，因为服务器要求较好的实时性，且要求能够同时处理多个客户请求的应用程序
	3）同步/异步线程分工
		<1>同步线程：处理客户业务请求（即逻辑单元）
		<2>异步线程：处理I/O事件（即I/O处理单元）
	4）半同步/半异步的变体 —— 半同步/半反应堆（half-sync/half-reactive）模式（项目中用到）
		half-reactive指的是基于Reactor 同步I/O模型，需要工作线程自己从请求队列中取出socket读取客户请求以及写入处理结果
		异步线程只有一个，就是主线程，主线程监听所有socket上的事件。
			* 若有“可读事件”发生，即有“新的连接请求到来”，主线程就接受之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的“可读事件”（即主线程往内核注册事件的操作由可读事件驱动）
			* 若连接socket上有“读写事件”发生，即有“新的客户请求到来或有数据要发送至客户端”，主线程就将该连接socket插入请求队列中。
		所有工作线程都睡眠在请求队列上，当有任务到来时，它们将通过竞争（比如申请互斥锁）获得任务的接管权
		5）半同步/半异步并发模式的缺陷
			<1>主线程和工作线程共享请求队列。主线程添加/工作线程取出任务时都需要对请求队列加锁保护，浪费CPU时间
			<2>每个工作线程在同一时间只能处理一个客户请求。若客户数较多，工作线程较少，会导致请求队列堆积任务对象，降低客户端响应速度（增加工作线程会导致线程切换，浪费CPU时间）
		6）高效的半同步/半异步模式
			主线程向工作线程派发连接socket（比如通过往管道里写数据实现派发），每个工作线程可能同时分发到多个连接socket，并通过对连接socket调用epoll_wait来监听该socket是否有客户请求到达，从而可以同时处理多个客户连接。

4.领导者/追随者模式（项目中没用到）
	1）定义：多个工作线程轮流获得事件源集合，轮流监听、分发并处理事件。
	2）工作模式：在任意时间点，程序都仅有一个领导者线程，它负责监听I/O事件。而其他线程则都是追随者，它们休眠在线程池中等待成为新的领导者。当前的领导者如果检测到I/O事件，首先要从线程池中推选出新的领导者线程，然后处理I/O事件。此时，新的领导者等待新的I/O事件，而原来的领导者则处理I/O事件

----------------------------------高效的逻辑处理方式-有限状态机-------------------------------
1.“逻辑单元”内部的高效编程方法：有限状态机（finite state machine）
	1）实现机制：有的应用层协议头部包含数据包类型字段，每种类型可以映射为逻辑单元的一种执行状态，服务器可以根据它来编写相应的处理逻辑
	2）状态之间可能会进行转移
		比如解析http请求时根据读取行的不同情况进行状态转移:
										 LINE_OPEN
											 ^
											 |  未读取到完整请求
		LINE_OK --> 新的客户数据到达 --> LINE_OPEN --> 回车和换行字符分开或单独出现在http请求中 --> LINE_BAD                                 |
											 v  读取到回车和换行字符
										   LINE_OK

----------------------------------提高服务器性能的几个建议----------------------------------
1.池（pool）—— 静态资源分配
	1）原理：池是一组资源的集合，这组资源在服务器启动之初就被完全创建好并初始化，这称为静态资源分配。当服务器进入正式运行阶段，即开始处理客户请求的时候，如果它需要相关的资源，就可以直接从池中获取，无须动态分配（从池中获取资源比动态分配速度快读多）。处理完一个客户请求，将该资源放回池中，无需释放资源，从而避免了对内核的频繁访问，提高了效率。
	2）本质：以空间换时间：通过服务器的硬件资源，换取运行效率。
	3）类型：
		<1>内存池。用于socket的接收缓存和发送缓存
		<2>进程池、线程池。当我们需要一个工作进程或工作线程来处理新到来的客户请求时，我们可以直接从进程池或线程池中取得一个执行实体，而无须动态地调用fork或pthread_create等函数来创建进程和线程
		<3>连接池。用于服务器或服务器机群的内部永久连接

2.数据复制
	高性能服务器应该避免不必要的数据复制，尤其是当数据复制发生在用户代码和内核之间的时候。如果内核可以直接处理从socket或者文件读入的数据，则应用程序就没必要将这些数据从内核缓冲区复制到应用程序缓冲区中。
	用户代码内部（不访问内核）的数据复制也是应该避免的。例如当两个工作进程之间要传递大量的数据时，我们就应该考虑使用共享内存来在它们之间直接共享这些数据，而不是使用管道或者消息队列来传递。

3.上下文切换和锁
	1）上下文切换问题：即进程切换或线程切换导致的的系统开销，线程切换会占用CPU时间，太多的线程会导致服务器真正用于处理业务逻辑的CPU时间比重不足。因此，为每个客户连接都创建一个工作线程的服务器模型是不可取的（应该采用上面提到的高效半同步/半异步并发模式，允许一个工作线程并发处理多个客户的连接）。
	此外，多线程服务器的一个优点是不同的线程可以同时运行在不同的CPU上（即多CPU系统，或多核CPU也可以，不同核同时执行不同的线程，实现线程的“并行”执行）。当线程的数量不大于CPU的数目时，上下文的切换就不是问题了。

	2）共享资源的加锁保护
		因为由它引入的代码不仅不处理任何业务逻辑，而且需要访问内核资源。因此，服务器如果有更好的解决方案，就应该避免使用锁。如果服务器必须使用“锁”，则可以考虑减小锁的粒度，比如使用读写锁
		读写锁：读不会阻塞（可以多个线程同时读），只有当一个线程需要写入数据时，才加锁保护并阻塞其它线程的访问


------------------------------------I/O复用---------------------------------------------------
1.I/O复用的作用：使得程序能同时监听多个文件描述符，从而提高服务器性能

2.I/O复用的应用场景（项目中使用的）
	1）TCP服务器需要同时处理监听socket和连接socket
	2）服务器需要同时监听多个端口，处理多种服务（每个socket都是通过bind()和一个端口绑定的）

3.特性
	1）能够同时监听多个文件描述符，但本身是阻塞的。
	2）如果多个文件描述符同时就绪，若无额外措施，程序只能按顺序处理（串行工作），所以需要“并发”技术，提高效率

4.I/O复用系统调用方法（主要有3种，项目中使用了epoll，为什么？三者有什么区别？）
	1）select
		<1>作用：在一段指定时间内，监听用户感兴趣的文件描述符上的可读、可写和异常等事件
		<2>判断文件描述符就绪的条件：P316给出了可读、可写和异常的几种情况
			例如：
			可读：监听socket有新的连接请求、socket接收内核缓存区字节数大于或等于低水位标记SO_RCVLOWAT，代表此时可无阻塞读取socket，且读操作返回字节数大于0等
			可写：socket内核发送缓存区中的可用字节数大于或等于其低水位标记SO_SNDLOWAT。此时我们可以无阻塞地写该socket，并且写操作返回的字节数大于0
			异常：socket上接收到带外数据
		<3>返回值：返回就绪的文件描述符数量

	2）poll
		<1>作用：和select类似，也是在指定时间内轮询一定数量的文件描述符，测试其中是否有就绪事件
		<2>判断就绪条件：标准规定了poll支持的事件类型。
		<3>返回值含义；返回值和select含义相同

	3）epoll
		<1>工作原理：使用一组函数（epoll_create、epoll_ctl、epoll_wait）而非单个函数（select/poll）完成任务；且将用户关心的一组文件描述符的事件放在内核的一个事件表中，通过额外的文件描述符epfd进行标识（这样就不用像select/poll那样每次调用都要重复传入文件描述符集/事件集，浪费资源）
		<2>主要函数
			* epoll_create：创建标识内核事件表的文件描述符
			* epoll_ctl：操作epoll的内核事件表：在事件表中为某个文件描述符——添加/修改/删除事件
			* epoll_wait：系统调用主接口，在一段超时时间内等待一组文件描述符上的事件
		<3>操作模式
			* 电平触发（LT）
				当epoll_wait检测到其上有事件发生并将此事件通知应用程序后，应用程序可以不立即处理该事件。这样，当应用程序下一次调用epoll_wait时，epoll_wait还会再次向应用程序通告此事件，直到该事件被处理。
			* 边沿触发（ET）—— 高效的epoll工作模式
				当epoll_wait检测到其上有事件发生并将此事件通知应用程序后，应用程序必须立即处理该事件，因为后续的epoll_wait调用将不再向应用程序通知这一事件。

		<4>EPOLLONESHOT事件
			* 解决问题：在并发程序中，一个线程（或进程，下同）在读取完某个socket上的数据后开始处理这些数据，而在数据的处理过程中该socket上又有新数据可读（EPOLLIN再次被触发），此时另外一个线程被唤醒来读取这些新的数据。于是就出现了两个线程同时操作一个socket的局面。但我们期望一个socket连接在任一时刻都只被一个线程处理！！
				为什么？
				1.主要是为了保证连接的完整性，避免竞态条件（这会导致数据的发送和接收出现不可预测的结果。
				2.降低资源管理复杂度（多线程同时处理一个socket时，需要访问同一块资源，需要额外的同步机制来避免资源冲突，一般就是加锁，但加锁又会导致服务器性能的降低，能够通过别的机制解决的问题，尽量不要加锁）
				3.减少上下文切换开销，提高性能
			* 解决方案：注册了EPOLLONESHOT事件的文件描述符，操作系统最多触发其上注册的一个可读、可写或者异常事件，且只触发一次，除非使用epoll_ctl重置EPOLLONESHOT事件（所以该线程处理完毕socket后，需要重置事件，否则当该socket再次就绪时，其它线程后续无法处理该socket！）

5.三种I/O复用的比较
	1）共同点：都能同时监听多个文件描述符。都将等待由timeout参数指定的超时时间，直到一个或者多个文件描述符上有事件发生时返回，返回值是就绪的文件描述符的数量。返回0表示没有事件发生
	
	2）区别：主要在于5个方面
		<1>事件集合
			* select通过三个参数分别传入可读、可写和异常事件，用户每次调用都需要重置三个参数，且接口复杂，不能处理更多类型的事件
			* poll统一定义文件描述符和事件，接口简洁，且因为内核修改的是pollfd结构体中的revents成员，events成员不变，因此每次调用无需重置事件集参数
			* epoll则完全不同，在内核维护一个事件表，通过一个文件描述符进行索引，并提供独立的函数epoll_ctl进行事件的添加、修改和删除
		<2>应用程序索引就绪文件描述符的复杂度
			* select和poll每次调用都返回整个事件集合（包括就绪和未就绪的），因此需要线性查找，索引复杂度为O(n)；epoll只返回就绪事件集合，索引复杂度为O(1)
		<3>工作模式
			* select和poll仅支持LT模式，相对低效（因为会多次触发，消耗资源）
			* epoll支持LT和ET，ET模式更加高效，且还支持EPOLLONESHOT事件进一步降低事件触发次数，提高效率
		<4>最大支持文件描述符数量
			* select允许监听的最大文件描述符数量通常有限制，不能达到65535
			* poll和epoll_wait分别用nfds和maxevents参数指定最多监听多少个文件描述符和事件。这两个数值都能达到系统允许打开的最大文件描述符数目，即65535（cat/proc/sys/fs/file-max）
		<5>内核实现和工作效率
			* select和poll通过轮询扫描整个注册文件描述符集合，并将就绪文件描述符返回应用程序，复杂度是O(n)
			* epoll_wait则基于回调，内核检测到就绪函数时触发回调函数并将事件插入就绪事件队列，并拷贝到用户空间，复杂度是O(1)。但活动连接较多时，回调函数触发频繁会降低效率。因此epoll适用于连接数多、活动连接数少的场景
	
--------------------------------------信号--------------------------------------------------
1.什么是信号？
	信号是由用户、系统或者进程发送给目标进程的信息，通知目标进程 “某个状态的改变” 或 “系统异常”
	例如：ctrl+C发送中断信号，alarm定时器引起SIGALRM信号，运行kill命令可以给进程发送信号
	
	网络编程相关的信号：SIGHUP、SIGPIPE、SIGURG
	其它重要信号：SIGALRM、SIGCHLD

2.信号处理方式
	目标进程在收到信号时，需要定义一个接收函数来处理，并通过signal或sigaction系统调用该接收函数

3.信号集
	1）linux使用结构体sigset_t表示一组信号（内部元素是数组，每个元素的每个位表示一个信号，表示方式和文件描述符集fd_set类似）
		通过一组函数设置、修改、删除和查询信号集：
		sigemptyset：清空信号集
		sigfillset：在信号集中设置所有信号
		sigaddset：将某个信号添加至信号集中
		sigdelset：将某个信号从信号集中删除
		sigismember：测试某个信号是否在信号集中

	2）进程信号掩码
		作用：设置进程的信号掩码，可以指定哪些信号不能发送给本进程（屏蔽信号）
		设置方法：sigaction结构体的sa_mask成员，或sigprocmask函数

	3）被挂起的信号
		设置进程信号掩码后，被屏蔽的信号将不能被进程接收。如果给进程发送一个被屏蔽的信号，则操作系统将该信号设置为进程的一个被挂起的信号。如果我们取消对被挂起信号的屏蔽，则它能立即被进程接收到
		

4.统一事件源
	定义：让信号事件和其它I/O事件被一样地处理。
	实现方式和原因：
	1）信号是一种异步事件：信号处理函数和程序的主循环是两条不同的执行路线
	2）为了避免信号被屏蔽，信号处理函数需要尽快执行完毕，典型解决方法是：
		把信号的主要处理逻辑放到程序的主循环中，当信号处理函数被触发时，它只是简单地通知主循环程序接收到信号，并把信号值传递给主循环，主循环再根据接收到的信号值执行目标信号对应的逻辑代码（即由主循环进行信号逻辑处理，信号处理函数只负责返回信号值）
		信号处理函数通过“管道”将信号传递给主循环（信号处理函数写，主循环读），主循环通过I/O复用系统调用来监听管道读端文件描述符的可读事件，从而实现信号事件和I/O事件的相同处理模式。

5.网络编程相关信号
	1）SIGHUP
		当挂起进程的控制终端时，SIGHUP信号将被触发。对于没有控制终端的网络后台程序而言，它们通常利用SIGHUP信号来强制服务器重读配置文件。

	2）SIGPIPE
		默认情况下，往一个读端关闭的管道或socket连接中写数据将引发SIGPIPE信号。我们需要在代码中捕获并处理该信号，或者至少忽略它，因为程序接收到SIGPIPE信号的默认行为是结束进程，而我们绝对不希望因为错误的写操作而导致程序退出。引起SIGPIPE信号的写操作将设置errno为EPIPE。

		所以可以利用SIGPIPE的特性，通过send函数反馈的errno值来检测管道或socket的读端是否关闭，还可以利用I/O复用系统调用来检测，以poll为例，当管道的读端关闭时，写端文件描述符上的POLLHUP事件将被触发；当socket连接被对方关闭时，socket上的POLLRDHUP事件将被触发。

	3)SIGURG
		内核通知应用程序带外数据到达主要有两种方法：
		* I/O复用技术中，select等系统调用在接收到带外数据时将返回，并向应用程序报告socket上的异常事件
		* 或者使用SIGURG信号

	带外数据：用于迅速通知对方本端的重要事件，比普通数据优先级更高，总是被立即发送而不论发送缓冲区是否由排队等待发送的普通数据。如TCP的紧急指针传输紧急数据（实际不是带外数据，但含义类似，所以也叫带外数据）


--------------------------------------------定时器-------------------------------------------
1.定时事件
	1）定时：在一段时间之后触发某段代码的机制，我们可以在这段代码中依次处理所有到期的定时器
	2）目的：有效地组织定时事件，使之能“在预期的时间点被触发且不影响服务器的主要逻辑”，对于服务器的性能有着至关重要的影响
	3）管理方法：将每个定时事件分别封装成定时器，并使用某种容器类数据结构，比如链表、排序链表和时间轮，将所有定时器串联起来，以实现对定时事件的统一管理。
	4）两种高效的定期器管理容器：时间轮、时间堆

2.定时方法
	1）socket选项SO_RCVTIMEO和SO_SNDTIMEO
		<1>说明：二者分别用于设置socket接收数据超时时间和发送数据超时时间，因此仅对与数据接收和发送相关的socket专用系统调用有效，包括send、sendmsg、recv、recvmsg、accept和connect。
		<2>如何判断是否超时：根据系统调用的返回值以及errno判断，并决定是否开始处理超时任务
	
	2）SIGALRM信号（项目中用到的）
		<1>说明：由alarm和setitimer函数设置的实时闹钟一旦超时，将触发SIGALRM信号。如果要处理多个定时任务，我们就需要不断地触发SIGALRM信号，并在其信号处理函数中执行到期的任务
		<2>一种简单的定时器实现：基于升序链表的定时器
			* 成员：至少包含超时时间和任务回调函数。
			* 缺陷：
				* 效率低，时间复杂度为O(n) —— 可以利用最小堆结构改进为O(logn)
				* 以固定时间触发SIGALRM信号，处理超时连接可能会造成一定的触发浪费 —— 可以将触发周期动态地设置为“当前最先超时的定时器与当前时间的时间差”（即相对时间而非绝对时间），这样可以保证每次触发都可以处理一个定时任务，然后再更新触发周期
		<3>应用场景：处理非活动连接	
			说明：服务器程序通常要定期处理非活动连接：给客户端发一个重连请求，或者关闭该连接，或者其他。内核中提供了定期检查连接活动状态的机制（socket的KEEPALIVE选项），那为什么还要在应用层实现非活动连接处理？
			因为使用内核的定期检查机制会使得应用程序的连接管理变得复杂，所以可以考虑在应用层实现类似的机制，管理长时间处于非活动状态的连接（一般的处理是关闭非活动连接）。

	3）I/O复用系统调用的超时参数
		<1>3类I/O复用系统调用都有超时参数，因此不仅能统一处理信号和I/O事件（前面提到的统一信号源实现方式），也能统一处理定时事件。但因为系统调用可能在超时时间到期之前返回（I/O事件发生），因此需要不断更新定时参数来反映剩余时间
	
3.高性能定时器
	1）时间轮 —— 基于哈希表拉链法的思想对定期器进行散列，解决基于升序链表的定时器添加效率偏低的问题
		<1>原理：时间轮有N个槽，每隔si（slot interval）转动一个槽，且每个槽指向一条定时器链表，每条链表上的定时器具备相同的特征：定时时间相差N*si的整数倍，通过这个关系可以将定时器散列到不同的链表中，插入效率基本不受定时器数目影响（基于排序链表的受数目影响很大）
		即假如当前槽指向cs，添加一个定时时间为ti的定时器，其对应的槽ts应该为	
							ts = (cs + ti/si) % N
		<2>参数对性能的影响：
			* 提高定时精度：si足够小
			* 提高执行效率：N足够大
		<3>复杂度
			* 添加一个定时器的时间复杂度是O(1)，删除一个定时器的时间复杂度也是O(1)，执行一个定时器的时间复杂度是O(n)（实际小于O(n)，因为散列到不同链表上，链表长度肯定小于n）
			* 当使用多个轮子来实现时间轮时，执行一个定时器任务的时间复杂度将接近O(1)
		<4>复杂时间轮：多个轮子，不同轮子有不同的精度，相邻的两个轮子，高精度(si小)轮子转一圈，精度低的仅移动一个槽（类似水表）

	2）时间堆
		1）原理：将超时时间最小的定时器的超时时间设置为触发周期（心搏间隔），一旦心搏函数tick被调用，超时时间最小的定时器必然到期，从而避免了无效触发。
		2）实现：基于最小堆（结点值必然小于或等于孩子结点值的完全二叉树），每次只需要更新堆顶元素即可。一般基于数组实现，便于更新，因此还需要堆数组扩容函数（对于动态数组vector则无需此操作）
		3）复杂度：添加一个定时器的时间复杂度是O(logn)，删除一个定时器的时间复杂度是O(1)，执行一个定时器的时间复杂度是O(1)

---------------------------------多进程编程（项目没用）----------------------------------------
具体可以看牛客视频的笔记-多进程编程一节

包含概念：
	1.什么是进程？并行和并发的概念，进程控制块（PCB）
		进程是一个正在运行的应用程序。
		PCB：内核分配，用于对进程所做事情进行清楚的描述
	2.进程的状态模型（三态/五态），进程相关命令
		三态模型：运行态、就绪态、阻塞态
		五态模型：新建态->就绪态，运行态->终止态
		查看进程：
			静态：ps，stat
			动态：top
		杀死进程：kill
	3.进程创建：fork，创建子进程，父子进程：读时共享（数据一样），写时拷贝（只要“有过”写操作，则后续不再共享数据）
	4.进程取代：exec函数族，在进程内部执行一个可执行文件，用它来取代调用进程的内容（即不再执行函数后面的进程内容），执行后不返回，除非执行失败
	5.进程控制
		进程退出：exit()（c函数库）；_exit()（linux）
		孤儿进程：父进程结束，子进程仍运行。无危害，因为出现孤儿进程时，内核设置其父进程为init，会循环调用wait()，以释放子进程资源
		僵尸进程：进程终止时，父进程未回收，子进程残留资源（PCB）存放于内核中，且僵尸进程不能被kill -9杀死，危害：保留资源不被释放，进程号一直被占用，大量僵尸进程导致无可用进程号而系统不能产生新的进程
	6.进程回收：释放所有资源-打开的文件、占用的内存，但保留PCB信息
		通过wait或waitpid完成，一次只能清理一个子进程，多个子进程清理应用循环
	7.进程间通信（IPC）
		Unix的IPC：匿名管道、有名管道、信号
		System V/POSIX进程间通信：消息队列、共享内存、信号量

---------------------------------多线程编程（项目使用）----------------------------------------
都基于POSIX线程规范（简称pthread）

1.主要内容
	1）创建线程、结束线程
	2）读取、设置线程
	3）POSIX线程同步方式：POSIX信号量、互斥锁、条件变量

2.定义
	线程是一个进程中的不同执行路径，是进程的“最小执行单位”，没有独立的地址空间，一个线程死掉整个进程都会死掉。一个进程的所有执行线程共享该进程的时间片（CPU调度的最小单位-进程）

3.线程相关函数
	创建：pthread_create
	退出：pthread_exit
	回收线程：pthread_join，类似于进程回收函数wait和waitpid
	取消线程（异常终止一个线程）：pthread_cancel

4.线程同步机制：
	1）POSIX信号量
		* 目的：保护关键代码段，确保其独占式访问
		* 原理：类似二进制，当信号量值为1，多个线程都有机会进入关键代码段，若线程A进入（执行了sem_wait），则将信号量-1，信号量减小为0，其它调用sem_wait的线程被阻塞，直到线程A完成操作，并执行sem_post将信号量+1，此后信号量非0，其余线程可以进入关键代码段。
		* 常用POSIX信号量函数：
		sem_init：初始化未命名信号量
		sem_destroy：销毁信号量，释放占用内核资源
		sem_wait：以原子操作方式将信号量的值减1，若信号量值为0，则sem_wait阻塞直到信号量非零  
			原子操作：多线程环境中，一个操作在执行过程中不能被其他线程中断，要么全部完成，要么全部不执行，不存在中间状态。这种操作是线程安全的，因为它保证了在执行过程中数据的一致性和完整性。
		sem_trywait：和sem_wait类似，立即返回，相当于sem_wait的非阻塞版本
		sem_post：以原子操作的方式将信号量的值加1

	2）互斥锁（互斥量）
		* 目的：保护关键代码段，确保其独占式访问。主要是用于同步线程对共享数据的访问
		* 主要函数：和信号量的含义差不多。
		pthread_mutex_init
		pthread_mutex_destroy
		pthread_mutex_lock
		pthread_mutex_trylock
		pthread_mutex_unlock

		* 死锁
			原因：
				* 忘记释放锁
				* 重复加锁（个人感觉原因和第三种类似）
				* 多线程多锁，抢占锁资源（阻塞是因为有可能一把锁解锁了，但另外一把锁还锁着，所以其它线程无法进入函数）
			结果
				使得一个或多个线程被挂起而无法继续执行，而且这种情况还不容易被发现

	3）条件变量
		* 目的：保护关键代码段，确保其独占式访问。主要是用于在线程之间“同步共享数据的值”
		* 提供“线程间通知机制”：当某个共享数据达到某个值的时候，唤醒等待这个共享数据的线程
		* 主要函数
			pthread_cond_init
			pthread_cond_destroy
			pthread_cond_broadcast：以广播方式唤醒所有等待目标条件变量的线程
			pthread_cond_signal：用于唤醒一个等待目标条件变量的线程
			thread_cond_wait：用于等待目标条件变量

	线程安全（可重入函数）：一个函数能够被多个线程同时调用而不发生竞态条件。

	多线程的主进程创建子进程的问题
		子进程只会有一个子线程，并继承父进程的互斥锁（条件变量/信号量）等状态，需要额外的函数进行清理工作。

5.线程和信号
	由于进程中的所有线程共享该进程的信号(且共享信号处理函数)，所以线程库将根据线程掩码决定把信号发送给哪个具体的线程。因此，如果我们在每个子线程中都单独设置信号掩码，就很容易导致逻辑错误
	所有线程共享信号处理函数。也就是说，当我们在一个线程中设置了某个信号的信号处理函数后，它将覆盖其他线程为同一个信号设置的信号处理函数。
	这两点都说明，我们应该定义一个专门的线程来处理所有的信号。

----------------------------------------进程池和线程池-------------------------------------
1.使用进程池和线程池的原因
	1）动态创建进程（或线程）是比较耗费时间的，这将导致较慢的客户响应
	2）动态创建的子进程（或子线程）通常只用来为一个客户服务（除非我们做特殊的处理），这将导致系统上产生大量的细微进程（或线程）。进程（或线程）间的切换将消耗大量CPU时间
	3）动态创建的子进程是当前进程的完整映像。当前进程必须谨慎地管理其分配的文件描述符和堆内存等系统资源，否则子进程可能复制这些资源，从而使系统的可用资源急剧下降，进而影响服务器的性能

2.进程池（和线程池类似，书中以进程池为例讲解）
	1）进程池是由服务器预先创建的一组子进程，这些子进程的数目在3～10个之间（当然，这只是典型情况）
	2）当有新的任务到来时，主进程将通过某种方式选择进程池中的某一个子进程来为之服务
		选择方式：
		<1>主进程通过算法选择（随机、轮询或其它算法）
		<2>主进程和所有子进程通过一个共享的工作队列来同步，子进程都睡眠在该工作队列上。当有新的任务到来时，主进程将任务添加到工作队列中。这将唤醒正在等待任务的子进程，不过只有一个子进程将获得新任务的“接管权”
	3）选择好子进程后，主进程还需要使用某种通知机制告诉目标子进程有新任务要处理，并传递必要数据
		传递方法：如预先建立管道，通过管道实现（对于父子线程的数据传递则简单得多，可以将数据定义为全局的，被所有线程共享）

3.处理多客户
	需要考虑的问题：
	1）监听socket和连接socket是否都由主进程来统一管理
		即对应不同的并发模式，比如半同步/半反应堆模式（半同步/半异步的变体）通过主进程统一管理两种socket；而高效的半同步/半异步模式，以及管理者/追随者模式，由主进程管理监听socket，由子进程管理属于自己的连接socket
	2）一个客户连接上的所有任务是否始终由一个子进程来处理
		<1>若客户是无状态的（即不存在上下文关系），可以用不同的子进程处理客户的不同请求
		<2>若客户任务存在上下文关系，则最好使用一个子进程处理所有请求，否则需要在进程间传递上下文数据，比较麻烦（如epoll的EPOLLONESHOT事件，就是确保一个客户连接的所有请求在整个生命周期中仅由一个线程处理）

4.多进程实现CGI（通用网关接口，用于实现用户登录/注册的校验）

5.半同步/半反应堆线程池实现
	1）实现方式：通过“工作队列”解除主线程和工作线程的耦合关系（即由主线程统一管理监听socket和连接socket，工作线程只负责处理客户请求如http解析），主线程往工作队列插入任务，工作线程通过竞争来取得任务并执行它
	2）条件：要求客户请求是无状态的，因为同一个连接上的不同请求可能由不同的线程处理（这里的实现不是高效的半同步半异步并发模式）
	这也是项目中的实现，因为“http请求是无状态的”。
	无状态协议的好处：
		* 服务器不需要为客户端维护状态信息，从而服务器可以轻松处理大量并发请求
		* 简化服务器设计，因为不需要实现复杂的状态管理机制
		* 容错性好，如果请求因为某些原因失败，不会影响后续的请求
	如何管理状态？（无状态无法维持会话信息，比如用户登录状态）
		* cookies：客户端会在请求中发送小段数据（cookies），服务器可以使用它们来识别和维持状态
		* session：服务器可以为每个用户会话生成一个唯一的session ID，并在服务器端存储会话信息
		* token认证：客户端在请求中发送token，服务器通过token验证用户状态


